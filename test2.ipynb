{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cc3cebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import numpy as np\n",
    "import math\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import importlib\n",
    "\n",
    "import nets.masked_autoencoder.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dda36a9",
   "metadata": {},
   "source": [
    "Download CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8699d561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar = datasets.CIFAR10(root=\"data\", download=True, transform=ToTensor())\n",
    "data_loader = DataLoader(cifar, batch_size=8, shuffle=True)\n",
    "X, y = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "54c50706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_shit():\n",
    "    importlib.reload(nets.masked_autoencoder.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "124bc725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [ 0.8415,  0.8219,  0.8020,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [ 0.9093,  0.9364,  0.9581,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         ...,\n",
      "         [-0.9661,  0.7486,  0.2145,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.7392, -0.1185,  0.9115,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [ 0.1674, -0.8836,  0.8744,  ...,  1.0000,  1.0000,  1.0000]]])\n"
     ]
    }
   ],
   "source": [
    "reload_shit()\n",
    "MAE = nets.masked_autoencoder.model.MaskedAutoEncoder\n",
    "mae = MAE(img_size=32, patch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8d439686",
   "metadata": {},
   "outputs": [],
   "source": [
    "ree = mae(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d08554ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 64, 512])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ree.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb66cf0f",
   "metadata": {},
   "source": [
    "What do I need to do for embedding? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a9281ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = t.tensor([[1, 2, 3], [4, 5, 56]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84ce9626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3],\n",
       "        [ 4,  5, 56]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.repeat([1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b3656e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = t.tensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ff5e882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  4,  6],\n",
       "        [ 5,  7, 59]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w + r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "46160f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = t.randn((2, 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f5fbc285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8868, -0.1843, -1.0674],\n",
       "         [ 0.7272, -0.1691,  1.1926]],\n",
       "\n",
       "        [[-2.9163,  2.1832,  0.3391],\n",
       "         [ 0.7245,  0.9055, -1.4451]]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e64fd0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 10.8868,   9.8157,   8.9326],\n",
       "         [ -9.2728, -10.1691,  -8.8074]],\n",
       "\n",
       "        [[  7.0837,  12.1832,  10.3391],\n",
       "         [ -9.2755,  -9.0945, -11.4451]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w + t.tensor([[10,10, 10], [-10, -10, -10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6fce257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "869f3fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54030231, 0.99997952, 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cos((64 / 10000) ** a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "add43f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8868, -0.1843, -1.0674],\n",
       "         [ 0.7272, -0.1691,  1.1926]],\n",
       "\n",
       "        [[-2.9163,  2.1832,  0.3391],\n",
       "         [ 0.7245,  0.9055, -1.4451]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7cc14d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8868, -0.1843, -1.0674],\n",
       "         [ 0.7272, -0.1691,  1.1926],\n",
       "         [ 0.8868, -0.1843, -1.0674],\n",
       "         [ 0.7272, -0.1691,  1.1926]],\n",
       "\n",
       "        [[-2.9163,  2.1832,  0.3391],\n",
       "         [ 0.7245,  0.9055, -1.4451],\n",
       "         [-2.9163,  2.1832,  0.3391],\n",
       "         [ 0.7245,  0.9055, -1.4451]]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.concat([w, w], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "49ef5989",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = t.randn(10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "823cfbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7175, -0.4684],\n",
       "        [-1.9177,  2.0047],\n",
       "        [ 0.1515,  0.2165],\n",
       "        [-1.2575,  0.4641],\n",
       "        [-0.5013,  1.0314],\n",
       "        [ 0.4337,  1.4199],\n",
       "        [-1.0745,  1.3987],\n",
       "        [-0.2096,  0.3717],\n",
       "        [-1.0850, -0.4827],\n",
       "        [-0.9914,  0.1761]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7b8b5a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7175, -0.4684,  0.7175, -0.4684],\n",
       "        [-1.9177,  2.0047, -1.9177,  2.0047],\n",
       "        [ 0.1515,  0.2165,  0.1515,  0.2165],\n",
       "        [-1.2575,  0.4641, -1.2575,  0.4641],\n",
       "        [-0.5013,  1.0314, -0.5013,  1.0314],\n",
       "        [ 0.4337,  1.4199,  0.4337,  1.4199],\n",
       "        [-1.0745,  1.3987, -1.0745,  1.3987],\n",
       "        [-0.2096,  0.3717, -0.2096,  0.3717],\n",
       "        [-1.0850, -0.4827, -1.0850, -0.4827],\n",
       "        [-0.9914,  0.1761, -0.9914,  0.1761]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.concat([v, v], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cad50f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.array(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c27a1df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.7175, 3.5316],\n",
       "        [2.0823, 6.0047],\n",
       "        [4.1515, 4.2165],\n",
       "        [2.7425, 4.4641],\n",
       "        [3.4987, 5.0314],\n",
       "        [4.4337, 5.4199],\n",
       "        [2.9255, 5.3987],\n",
       "        [3.7904, 4.3717],\n",
       "        [2.9150, 3.5173],\n",
       "        [3.0086, 4.1761]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.tensor(d) + v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f7a2801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nn.Parameter(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7ff0a41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.]]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.data.copy_(t.zeros(2, 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "23b11a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.]]], requires_grad=True)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a29c43a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.]]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1b8f418f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[2, 2, 1]' is invalid for input of size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [117]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m t\u001b[38;5;241m.\u001b[39mgather(w, \u001b[38;5;241m1\u001b[39m, \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[2, 2, 1]' is invalid for input of size 2"
     ]
    }
   ],
   "source": [
    "t.gather(w, 1, t.tensor([1, 1]).reshape(2, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3c132f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
